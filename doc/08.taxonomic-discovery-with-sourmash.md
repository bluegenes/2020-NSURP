Taxonomic Discovery with Sourmash
===

Until now, we've performed general pre-processing steps on our sequencing data;
sequence quality analysis and trimming usually occur at the start of any sequencing data analysis pipeline.
Now we will begin performing analysis that makes sense for metagenomic sequencing data. 

We are working with publicly-available data, but let's pretend that this is a brand new sample that we just got back from our sequencing core. 
One of the first things we often want to do with new metagenome sequencing samples is figure out their approximate species composition. 
This allows us to tap in to all of the information known about these species and relate our community to existing literature. 

We can determine the approximate composition of our sample using `sourmash`. 

## Introduction to sourmash

Please read [this tutorial](https://angus.readthedocs.io/en/2019/sourmash.html) for an introduction to how sourmash works. 

tl;dr (but actually please read it): sourmash breaks nucleotide sequences down into k-mers, systematically subsamples those k-mers into a representative "signature", and then enables searches for those k-mers in databases.
This makes it really fast to make comparisons. Here, we will compare our metagenome sample against a pre-prepared database that contains all microbial sequences in GenBank.

## Workspace Setup

If you're starting a new work session on FARM, be sure to follow the instructions [here](05.starting-a-work-session.md).

## Starting with sourmash

Sourmash doesn't have a big memory or CPU footprint, and can be run on most laptops. 
Below is a recommended `srun` command to start an interactive session in which to run the `srun` commands.

```
srun -p bmh -J sourmash24 -t 24:00:00 --mem=16gb -c 1 --pty bash
```

### Install sourmash

*Be sure you've set up conda channels properly, as in the [Install Conda](02.conda.md) section*

```
conda activate nsurp-env
conda install -y sourmash
```

Next, let's create a directory in which to store our sourmash signatures

```
cd ~/2020-NSURP
mkdir -p sourmash
cd sourmash
```

## What data to use?

We could run sourmash with our adapter trimmed or k-mer trimmed data.
In fact, doing so would make sourmash faster because there would be fewer k-mers in the sample.

We are currently comparing our sample against a database of trusted DNA sequences, so any k-mers in our sample that contain adapters sequence or errors will not match to the trusted reference sequences in the database.
However, even though we very lightly trimmed our reads, there is a chance that we removed a very low abundance organism that was truly present in the sample.
Given this trade-off, we use often raw reads for reference data comparisons, and quality-controlled reads for all other comparisons.


For now, let's link in our raw data:

```
ln -s ~/2020-NSURP/raw_data/*fastq.gz .
```

## Generate a sourmash signature

Next, let's make sourmash signatures from our reads.

Remember from the [Quick Insights from Sequencing Data with sourmash](https://angus.readthedocs.io/en/2019/sourmash.html) tutorial that a k-mer size of 21 is approximately specific at the genus level, a 31 is at the species level, and 51 at the strain level. We will calculate our signature with all three k-mer sizes so we can choose which one we want to use later.

```
sourmash compute -o SRR1211157.raw.sig --merge SRR1211157 --scaled 2000 -k 21,31,51 --track-abundance SRR1211157_*fastq.gz
```

You should see output that looks like this:

```
== This is sourmash version 3.4.1. ==
== Please cite Brown and Irber (2016), doi:10.21105/joss.00027. ==

setting num_hashes to 0 because --scaled is set
computing signatures for files: SRR1211157_1.fastq.gz, SRR1211157_2.fastq.gz
Computing signature for ksizes: [21, 31, 51]
Computing only nucleotide (and not protein) signatures.
Computing a total of 3 signature(s).
Tracking abundance of input k-mers.
... reading sequences from SRR1211157_1.fastq.gz
... SRR1211157_1.fastq.gz 4028773 sequences
... reading sequences from SRR1211157_2.fastq.gz
... SRR1211157_2.fastq.gz 4028773 sequences
calculated 1 signatures for 8057546 sequences taken from 2 files
saved signature(s) to SRR1211157.raw.sig. Note: signature license is CC0.
```

The outputs file, `SRR1211157.raw.sig` holds a representative subset of k-mers from our original sample, as well as their abundance information. 
The k-mers are "hashed", or transformed, into numbers to make selecting, storing, and looking up the k-mers more efficient.

## Sourmash gather

`sourmash gather` is a method for estimating the taxonomic composition of known sequences in a metagenome.
Running it on our IBD samples can give us an idea of the microbes present in each sample.
 `gather` results provide strain-level specificity to matches in its output -- e.g. all strains that match any sequences (above a threshold) in your metagenome will be reported, along with the percent of each strain that matches. 
This is useful both to estimate the amount of metagenome sample that is known, and to estimate the closest strain relative to the organisms in your metagenomes.

### Download and unzip the database:

```
mkdir -p ~/2020-NSURP/databases/
cd ~/2020-NSURP/databases/
curl -L https://osf.io/jgu93/download -o genbank-k31.sbt.zip
cd ~/2020-NSURP/sourmash
```

### Run sourmash gather

First, let's run a very quick search:

```
sourmash gather --num-results 10 SRR1211157.raw.sig ~/2020-NSURP/databases/genbank-k31.sbt.zip
```

> - the `--num-results 10` is a way of shortening the search. In this case, we ask for only the top 10 results

We see an output that looks like this:

```
== Please cite Brown and Irber (2016), doi:10.21105/joss.00027. ==

selecting default query k=31.
loaded query: SRR1211157... (k=31, DNA)
loaded 1 databases.


overlap     p_query p_match avg_abund
---------   ------- ------- ---------
5.0 Mbp        5.8%   86.5%       6.5    BCAD01000001.1 Bacteroidia bacterium ...
3.4 Mbp        1.2%   68.6%       2.1    KQ087625.1 Escherichia coli strain BW...
3.0 Mbp        1.4%   47.4%       2.6    GL945090.1 Bacteroides sp. 1_1_30 gen...
2.9 Mbp        1.3%   37.8%       2.5    CZBJ01000001.1 [Ruminococcus] torques...
2.8 Mbp        2.1%   40.7%       4.4    KV804220.1 Bacteroides sp. HMSC067B03...
4.2 Mbp        2.3%   45.4%       5.3    JNHI01000001.1 Bacteroides vulgatus s...
2.5 Mbp        0.9%   48.5%       2.1    JH976452.1 Parabacteroides merdae CL0...
2.4 Mbp        1.0%   67.6%       2.4    AENZ01000086.1 Alistipes sp. HGB5 con...
2.4 Mbp        1.0%   48.4%       2.7    AXVN01000001.1 Blautia wexlerae DSM 1...
2.2 Mbp        0.8%   43.9%       2.2    JH724260.1 Bacteroides uniformis CL03...
```

The shortened search will be quite quick. 

The two columns to pay attention to are `p_query` and `p_match`.
`p_query` is the percent of the metagenome sample that is
(estimated to be) from the named organism.  `p_match` is the percent
of the database match that is found in the query.  
These metrics` are affected by both evolutionary distance and by low coverage of the
organism's gene set (low sequencing coverage, or little expression).


Now, let's run the full `gather` analysis:
This will take a long time to run.
Sourmash will also output a csv with all the results information that we will use later to visualize our results.

```
sourmash gather -o SRR1211157_x_genbank-k31.gather.csv SRR1211157.raw.sig ~/2020-NSURP/databases/genbank-k31.sbt.zip
```

When sourmash is finished running, it tells us the % of our sequence was unclassified; i.e. it doesn't match any sequence in the database.

In a later module, we may use another dib-lab program, [spacegraphcats](https://link.springer.com/article/10.1186/s13059-020-02066-4), to improve the percent of sequence in the metagenome that is classifiable.

## Other Methods for Taxonomic Discovery and Classification

There are many tools, such as Kraken and Kaiju, that can do taxonomic classification of individual reads from metagenomes.
These seem to perform well (albeit with high false positive rates) in situations where you donâ€™t necessarily have the genome sequences that are in the metagenome. 
Sourmash, by contrast, can estimate which known genomes are actually present, so that you can extract them and map/align to them. 
It seems to have a very low false positive rate and is quite sensitive to strains.

## Detecting contamination or incorrect data

sourmash `gather` taxonomic discovery can help uncover contamination or errors in your sequencing samples.
We recommend doing sourmash gather immediately after receiving your data from the sequencing facility.
If your environmental metagenome has a tremendous amount of mouse sequence in it... maybe the sequencing facility sent you the wrong data?

## Challenge: sourmash gather

### Gather with trimmed data

Above, we ran `sourmash gather` on our untrimmed data. 
XX% of the sample did not contain sequence in any GenBank assembly. 
A substantial proportion of this sequence could be due to errors.
Run `sourmash gather` again on your adapter/ k-mer trimmed data.
How much less of the sequence is unclassifiable when the errors and adapters are removed?
How many species are no longer detected after k-mer and error trimming?

### Gather at different ksizes

The genbank reference databases for signatures of ksize k=21 and k=51 are available for download.

k=21
```
cd ~/2020-NSURP/databases/
curl -L https://osf.io/dm7n4/download -o genbank-k21.sbt.zip
```

k=51
```
cd ~/2020-NSURP/databases/
curl -L https://osf.io/2uvsc/download -o genbank-k51.sbt.zip
```

How do you expect the gather results to differ for each? Why?

### Gather with different scaled factors

By running `sourmash gather --help`, you can see all the options for the `gather` program.


The `scaled` option provides a chaces to downample the query to the specified scaled factor.

```
  --scaled FLOAT        downsample query to the specified scaled factor
```

Try running gather with a `scaled` value of 10000. How do the results change, and why?
